{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/werverton/.pyenv/versions/3.6.2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/werverton/.pyenv/versions/3.6.2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/werverton/.pyenv/versions/3.6.2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/werverton/.pyenv/versions/3.6.2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/werverton/.pyenv/versions/3.6.2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/werverton/.pyenv/versions/3.6.2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0\n",
      "3.6.2 (default, Aug 31 2021, 22:53:44) \n",
      "[GCC 9.3.0]\n"
     ]
    }
   ],
   "source": [
    "#vamos usar a versão 3.6.2 do python, pois nessa versão é possível instalar o tf 1.12\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import logging\n",
    "logging.basicConfig(format=\"%(asctime) -15s %(message)s\")\n",
    "import sys\n",
    "print(sys.version)\n",
    "import queue\n",
    "import shutil\n",
    "import threading\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_json = {\n",
    "    \"training_data_dir\": \"/home/werverton/DATA/pickle_files\",\n",
    "    \"training_data_dir_test\": \"/home/werverton/DATA/pickle_files_test\",\n",
    "    \"validation_data_dir\": \"/home/werverton/DATA/validation_data\",\n",
    "    \"log_data_dir\": \"/home/werverton/DATA/training_log\",\n",
    "\n",
    "    \"training_dim\": 2,\n",
    "    \"predicting_dim\": 1,\n",
    "    \"total_interacts\": 7,\n",
    "\n",
    "    \"boundary_width\": 1,\n",
    "\n",
    "    \"downscale_dim\": [180, 320],\n",
    "    \"data_augmentation_threshold\": 1,\n",
    "\n",
    "    \"dataset_threads\": 100,\n",
    "    \"batch_size\": 64,\n",
    "    \"frame_num\": 4,\n",
    "\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"weight_decay\": 0.001,\n",
    "    \"log_step\": 200,\n",
    "    \"snapshot_step\": 5000,\n",
    "    \"max_iter\": 500000,\n",
    "\n",
    "    \"embedding_model\": \"model_495000.ckpt\",\n",
    "    \"embedding_dir\": \"/home/werverton/DATA/embedding\"\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loader():\n",
    "    \"\"\"Basic data loader\n",
    "    \"\"\"\n",
    "    def __init__(self, config_json):\n",
    "        self.x_dim, self.y_dim = config_json[\"downscale_dim\"]\n",
    "        self.training_dim = config_json[\"training_dim\"]\n",
    "        self.predicting_dim = config_json[\"predicting_dim\"]\n",
    "        self.total_interacts = config_json[\"total_interacts\"]\n",
    "        self.training_data_dir = config_json[\"training_data_dir\"]\n",
    "        self.logger = logging.getLogger(\"loader\")\n",
    "        self.logger.setLevel(logging.INFO)\n",
    "\n",
    "    def next_batch(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultipleScreenLoader(Loader):\n",
    "    \"\"\"Normal multiple screen data loader, in contrast to debug data loader\n",
    "    \"\"\"\n",
    "    def __init__(self, config_json, load_text=False):\n",
    "        super().__init__(config_json)\n",
    "        self.dataset_threads = config_json[\"dataset_threads\"]\n",
    "        self.batch_size = config_json[\"batch_size\"]\n",
    "        self.frame_num = config_json[\"frame_num\"]\n",
    "        self.data_files = next(os.walk(self.training_data_dir))[2]#alterei aqui tirando a variável\n",
    "        # self.data_files = [\"jp.naver.linecard.android.pickle\",\n",
    "        #                    \"co.brainly.pickle\"]\n",
    "        self.data_paths = [os.path.join(self.training_data_dir, x) for x in self.data_files]\n",
    "        self.data_queue = queue.Queue()\n",
    "        self.path_queue = queue.Queue()\n",
    "        self.epochs = -1\n",
    "        self.loading_thread = None\n",
    "        self.loading_thread_result = None\n",
    "        self.loading_thread_out = None\n",
    "        self.produce_threshold = 10000\n",
    "        self.stopped = False\n",
    "        self.load_text = load_text\n",
    "\n",
    "    def get_current_epoch(self):\n",
    "        return self.epochs\n",
    "\n",
    "    def reload_paths(self):\n",
    "        self.epochs += 1\n",
    "        self.logger.info(\"epoch: %d\", self.epochs)\n",
    "        random.shuffle(self.data_paths)\n",
    "        for data_path in self.data_paths:\n",
    "            self.path_queue.put(data_path)\n",
    "\n",
    "    def load_pickles(self, data_paths):\n",
    "        data_item_list = []\n",
    "        for data_path in data_paths:\n",
    "            with open(data_path, \"rb\") as f:\n",
    "                input_data = pickle.load(f)\n",
    "            # assemble frames\n",
    "            # do zero padding before the first image\n",
    "            for trace_key in input_data:\n",
    "                image_num = len(input_data[trace_key])\n",
    "                \n",
    "                if image_num == 0:\n",
    "                    continue\n",
    "                stacked_images = np.stack([np.zeros_like(input_data[trace_key][0][0], dtype=np.float32)] * (self.frame_num - 1) + \\\n",
    "                                          [x[0] for x in input_data[trace_key]], axis=0)\n",
    "                print(\"stacked: \",stacked_images)\n",
    "                images = [stacked_images[i:i + self.frame_num].copy() for i in range(image_num)]\n",
    "                #print(type(images))\n",
    "                #print(images)\n",
    "                # for each image, clear last heatmaps\n",
    "                for image in images:\n",
    "                    #print(\"one image: \",image)\n",
    "                    image[self.frame_num - 1, :, :, -self.predicting_dim:] = 0.0\n",
    "                    image -= 0.5\n",
    "                    # for i in range(self.frame_num):\n",
    "                    #     visualize_data(image[i])\n",
    "\n",
    "                heatmaps = [x[0][:,:,-self.predicting_dim:].copy() for x in input_data[trace_key]]\n",
    "                interacts = np.split(np.eye(self.total_interacts)[[x[1][\"interact_type\"] for x in input_data[trace_key]]],\n",
    "                                     image_num, axis=0)\n",
    "\n",
    "                if self.load_text:\n",
    "                    input_texts = []\n",
    "                    for x in input_data[trace_key]:\n",
    "                        if \"text\" in x[1]:\n",
    "                            input_texts.append(x[1][\"text\"])\n",
    "                        else:\n",
    "                            input_texts.append(None)\n",
    "                    zipped_data = zip(images, heatmaps, interacts, input_texts)\n",
    "                else:\n",
    "                    zipped_data = zip(images, heatmaps, interacts)\n",
    "\n",
    "                for data_item in zipped_data:\n",
    "                    data_item_list.append(data_item)\n",
    "        rand_idx = list(range(len(data_item_list)))\n",
    "        random.shuffle(rand_idx)\n",
    "        for i in rand_idx:\n",
    "            self.data_queue.put(data_item_list[i])\n",
    "\n",
    "    def next_batch_producer(self):\n",
    "        # always try to load data when < threshold\n",
    "        # poll check threshold\n",
    "        while not self.stopped:\n",
    "            if self.data_queue.qsize() < self.produce_threshold:\n",
    "                paths_to_load = []\n",
    "                for i in range(min(self.dataset_threads, len(self.data_paths))):\n",
    "                    if self.path_queue.empty():\n",
    "                        self.reload_paths()\n",
    "                    paths_to_load.append(self.path_queue.get())\n",
    "                    # self.logger.info(\"loading: %s\", paths_to_load[-1])\n",
    "                self.load_pickles(paths_to_load)\n",
    "            time.sleep(1)\n",
    "\n",
    "    def next_batch_consumer(self):\n",
    "        # always try to get data\n",
    "        batch_image_list = []\n",
    "        batch_heatmap_list = []\n",
    "        batch_interact_list = []\n",
    "        if self.load_text:\n",
    "            batch_input_text_list = []\n",
    "        for i in range(self.batch_size):\n",
    "            if self.load_text:\n",
    "                image, heatmap, interact, input_text = self.data_queue.get()\n",
    "            else:\n",
    "                image, heatmap, interact = self.data_queue.get()\n",
    "            batch_image_list.append(image)\n",
    "            batch_heatmap_list.append(heatmap)\n",
    "            batch_interact_list.append(interact)\n",
    "            if self.load_text:\n",
    "                batch_input_text_list.append(input_text)\n",
    "        if self.load_text:\n",
    "            return (np.concatenate(batch_image_list, axis=0), \\\n",
    "                    np.stack(batch_heatmap_list, axis=0), \\\n",
    "                    np.concatenate(batch_interact_list, axis=0), \\\n",
    "                    batch_input_text_list)\n",
    "        else:\n",
    "            return (np.concatenate(batch_image_list, axis=0), \\\n",
    "                    np.stack(batch_heatmap_list, axis=0), \\\n",
    "                    np.concatenate(batch_interact_list, axis=0))\n",
    "\n",
    "    def next_batch(self):\n",
    "        if self.loading_thread is None:\n",
    "            self.loading_thread = threading.Thread(target=self.next_batch_producer)\n",
    "            self.loading_thread.start()\n",
    "        return self.next_batch_consumer()\n",
    "\n",
    "    def stop(self):\n",
    "        self.stopped = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel():\n",
    "    \"\"\"Base model\n",
    "       Build CNN and LSTM units\n",
    "    \"\"\"\n",
    "    def __init__(self, config_json, training=True):\n",
    "        self.x_dim, self.y_dim = config_json[\"downscale_dim\"]\n",
    "        self.training_dim = config_json[\"training_dim\"]\n",
    "        self.predicting_dim = config_json[\"predicting_dim\"]\n",
    "        self.total_channels = self.training_dim + self.predicting_dim\n",
    "        self.total_interacts = config_json[\"total_interacts\"]\n",
    "        if training:\n",
    "            self.weight_decay = config_json[\"weight_decay\"]\n",
    "            self.batch_size = config_json[\"batch_size\"]\n",
    "            self.keep_prob = 0.5\n",
    "        else:\n",
    "            self.weight_decay = 0.0\n",
    "            self.batch_size = 1\n",
    "            self.keep_prob = 1.0\n",
    "        self.regularizer = tf.contrib.layers.l2_regularizer(scale=self.weight_decay)\n",
    "\n",
    "        self.input_images = None\n",
    "        self.true_heats = tf.placeholder(dtype=tf.float32,\n",
    "                                         shape=(None, self.x_dim, self.y_dim, self.predicting_dim))\n",
    "        self.true_interacts = tf.placeholder(dtype=tf.float32,\n",
    "                                             shape=(None, self.total_interacts))\n",
    "\n",
    "        # assign later\n",
    "        self.heatmap_out = None\n",
    "        self.interact_out = None\n",
    "\n",
    "    def get_feed_dict(self, images, heatmaps, interacts):\n",
    "        return {\n",
    "            self.input_images: images,\n",
    "            self.true_heats: heatmaps,\n",
    "            self.true_interacts: interacts\n",
    "        }\n",
    "\n",
    "    def build_cnn(self):\n",
    "        # First generate low-resolution heatmap\n",
    "        # 180x320\n",
    "        self.conv1 = tf.layers.conv2d(inputs=self.input_images,\n",
    "                                      filters=16,\n",
    "                                      kernel_size=3,\n",
    "                                      padding=\"same\",\n",
    "                                      activation=tf.nn.relu,\n",
    "                                      kernel_regularizer=self.regularizer,\n",
    "                                      bias_regularizer=self.regularizer,\n",
    "                                      name=\"conv1\")\n",
    "        self.pool1 = tf.layers.max_pooling2d(inputs=self.conv1,\n",
    "                                             pool_size=2,\n",
    "                                             strides=2,\n",
    "                                             name=\"pool1\")\n",
    "        # 90x160\n",
    "        self.conv2 = tf.layers.conv2d(inputs=self.pool1,\n",
    "                                      filters=32,\n",
    "                                      kernel_size=3,\n",
    "                                      padding=\"same\",\n",
    "                                      activation=tf.nn.relu,\n",
    "                                      kernel_regularizer=self.regularizer,\n",
    "                                      bias_regularizer=self.regularizer,\n",
    "                                      name=\"conv2\")\n",
    "        self.pool2 = tf.layers.max_pooling2d(inputs=self.conv2,\n",
    "                                             pool_size=2,\n",
    "                                             strides=2,\n",
    "                                             name=\"pool2\")\n",
    "        # 45x80\n",
    "        self.conv3 = tf.layers.conv2d(inputs=self.pool2,\n",
    "                                      filters=64,\n",
    "                                      kernel_size=3,\n",
    "                                      padding=\"same\",\n",
    "                                      activation=tf.nn.relu,\n",
    "                                      kernel_regularizer=self.regularizer,\n",
    "                                      bias_regularizer=self.regularizer,\n",
    "                                      name=\"conv3\")\n",
    "        self.pool3 = tf.layers.max_pooling2d(inputs=self.conv3,\n",
    "                                             pool_size=2,\n",
    "                                             strides=2,\n",
    "                                             padding=\"same\",\n",
    "                                             name=\"pool3\")\n",
    "        # 23x40\n",
    "        self.conv4 = tf.layers.conv2d(inputs=self.pool3,\n",
    "                                      filters=64,\n",
    "                                      kernel_size=3,\n",
    "                                      padding=\"same\",\n",
    "                                      activation=tf.nn.relu,\n",
    "                                      kernel_regularizer=self.regularizer,\n",
    "                                      bias_regularizer=self.regularizer,\n",
    "                                      name=\"conv4\")\n",
    "        self.pool4 = tf.layers.max_pooling2d(inputs=self.conv4,\n",
    "                                             pool_size=2,\n",
    "                                             strides=2,\n",
    "                                             padding=\"same\",\n",
    "                                             name=\"pool4\")\n",
    "        # 12x20\n",
    "        self.conv5 = tf.layers.conv2d(inputs=self.pool4,\n",
    "                                      filters=64,\n",
    "                                      kernel_size=3,\n",
    "                                      padding=\"same\",\n",
    "                                      activation=tf.nn.relu,\n",
    "                                      kernel_regularizer=self.regularizer,\n",
    "                                      bias_regularizer=self.regularizer,\n",
    "                                      name=\"conv5\")\n",
    "        self.pool5 = tf.layers.max_pooling2d(inputs=self.conv5,\n",
    "                                             pool_size=2,\n",
    "                                             strides=2,\n",
    "                                             padding=\"same\",\n",
    "                                             name=\"pool5\")\n",
    "        # 6x10\n",
    "\n",
    "        # generate heats, i.e. single channel output\n",
    "        self.pool3_heat = tf.layers.conv2d(inputs=self.pool3,\n",
    "                                           filters=1,\n",
    "                                           kernel_size=1,\n",
    "                                           padding=\"same\",\n",
    "                                           activation=tf.nn.relu,\n",
    "                                           kernel_regularizer=self.regularizer,\n",
    "                                           bias_regularizer=self.regularizer,\n",
    "                                           name=\"pool3_heat\")\n",
    "        self.pool4_heat = tf.layers.conv2d(inputs=self.pool4,\n",
    "                                           filters=1,\n",
    "                                           kernel_size=1,\n",
    "                                           padding=\"same\",\n",
    "                                           activation=tf.nn.relu,\n",
    "                                           kernel_regularizer=self.regularizer,\n",
    "                                           bias_regularizer=self.regularizer,\n",
    "                                           name=\"pool4_heat\")\n",
    "        self.pool5_heat = tf.layers.conv2d(inputs=self.pool5,\n",
    "                                           filters=1,\n",
    "                                           kernel_size=1,\n",
    "                                           padding=\"same\",\n",
    "                                           activation=tf.nn.relu,\n",
    "                                           kernel_regularizer=self.regularizer,\n",
    "                                           bias_regularizer=self.regularizer,\n",
    "                                           name=\"pool5_heat\")\n",
    "\n",
    "    def build_loss(self):\n",
    "        # heatmap loss\n",
    "        self.heatmap_loss = tf.losses.softmax_cross_entropy(\n",
    "            tf.reshape(self.true_heats, [-1, 180 * 320]),\n",
    "            tf.reshape(self.heatmap_out, [-1, 180 * 320]))\n",
    "        self.predict_heatmaps = tf.reshape(tf.nn.softmax(\n",
    "            tf.reshape(self.heatmap_out, [-1, 180 * 320])), [-1, 180, 320, 1])\n",
    "        # interact loss\n",
    "        self.interact_out_flat = tf.reshape(self.interact_out, [-1, 6 * 10 * 1])\n",
    "        self.fc = tf.layers.dense(self.interact_out_flat,\n",
    "                                  self.total_interacts,\n",
    "                                  activation=tf.nn.relu,\n",
    "                                  kernel_regularizer=self.regularizer,\n",
    "                                  bias_regularizer=self.regularizer,\n",
    "                                  name=\"fc\")\n",
    "        # self.fc_dropout = tf.layers.dropout(self.fc, name=\"fc_dropout\")\n",
    "        self.interact_loss = tf.losses.softmax_cross_entropy(self.true_interacts,\n",
    "                                                             self.fc)\n",
    "                                                             # self.fc_dropout)\n",
    "        self.predict_interacts = tf.nn.softmax(self.fc)\n",
    "\n",
    "        # total loss\n",
    "        # self.total_loss = tf.add(self.heatmap_loss, self.interact_loss, name=\"total_loss\")\n",
    "        # self.total_loss = self.heatmap_loss\n",
    "        self.total_loss = tf.losses.get_total_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultipleScreenModel(BaseModel):\n",
    "    \"\"\"Model for processing single screenshot\n",
    "       Use conv-pool-de-conv for heatmap\n",
    "       Use conv-pool-fc for predicting\n",
    "\n",
    "       input: batch_num, x_dim, y_dim, channels\n",
    "    \"\"\"\n",
    "    def __init__(self, config_json, training=True):\n",
    "        super().__init__(config_json, training)\n",
    "        self.frame_num = config_json[\"frame_num\"]\n",
    "        self.input_images = tf.placeholder(dtype=tf.float32,\n",
    "                                           shape=(None, self.x_dim, self.y_dim,\n",
    "                                                  self.training_dim + self.predicting_dim))\n",
    "        self.build_cnn()\n",
    "        self.build_model()\n",
    "        self.build_loss()\n",
    "        if training:\n",
    "            self.build_summary()\n",
    "\n",
    "    def build_model(self):\n",
    "        # generate heats\n",
    "        # using three LSTMs at different resolutions\n",
    "        # from pool3, pool4 and pool5\n",
    "\n",
    "        # pool3_heat_in: item_num (how many series), frame_num, x_dim * y_dim\n",
    "        self.pool3_heat_in = tf.reshape(self.pool3_heat, [-1, self.frame_num, 23 * 40])\n",
    "        self.pool4_heat_in = tf.reshape(self.pool4_heat, [-1, self.frame_num, 12 * 20])\n",
    "        self.pool5_heat_in = tf.reshape(self.pool5_heat, [-1, self.frame_num, 6 * 10])\n",
    "\n",
    "        # pool3_heat_out: item_num (how many series), x_dim, y_dim\n",
    "        self.pool3_heat_out = tf.add(\n",
    "            tf.reshape(\n",
    "            tf.keras.layers.LSTM(units=23 * 40, dropout=self.keep_prob)(self.pool3_heat_in),\n",
    "            # tf.keras.layers.LSTM(units=23 * 40)(self.pool3_heat_in),\n",
    "            [-1, 23, 40, 1]),\n",
    "            tf.reshape(self.pool3_heat,\n",
    "            [self.batch_size, self.frame_num, 23, 40, 1])[:, self.frame_num - 1, :,:,:])\n",
    "        self.pool4_heat_out = tf.add(tf.reshape(\n",
    "            tf.keras.layers.LSTM(units=12 * 20, dropout=self.keep_prob)(self.pool4_heat_in),\n",
    "            # tf.keras.layers.LSTM(units=12 * 20)(self.pool4_heat_in),\n",
    "            [-1, 12, 20, 1]),\n",
    "            tf.reshape(self.pool4_heat,\n",
    "            [self.batch_size, self.frame_num, 12, 20, 1])[:, self.frame_num - 1, :,:,:])\n",
    "        self.pool5_heat_out = tf.add(tf.reshape(\n",
    "            tf.keras.layers.LSTM(units=6 * 10, dropout=self.keep_prob)(self.pool5_heat_in),\n",
    "            # tf.keras.layers.LSTM(units=6 * 10)(self.pool5_heat_in),\n",
    "            [-1, 6, 10, 1]),\n",
    "            tf.reshape(self.pool5_heat,\n",
    "            [self.batch_size, self.frame_num, 6, 10, 1])[:, self.frame_num - 1, :,:,:])\n",
    "\n",
    "        # do upsampling\n",
    "        # 6x10\n",
    "        self.pool5_up_filters = tf.get_variable(\"pool5_up_filters\", [4, 4, 1, 1], regularizer=self.regularizer)\n",
    "        self.pool5_up = tf.nn.relu(tf.nn.conv2d_transpose(value=self.pool5_heat_out,\n",
    "                                   filter=self.pool5_up_filters,\n",
    "                                   output_shape=[self.batch_size, 12, 20, 1],\n",
    "                                   strides=[1, 2, 2, 1],\n",
    "                                   name=\"pool5_up\"))\n",
    "        # 12x20\n",
    "        self.pool4_heat_sum = tf.add(self.pool5_up, self.pool4_heat_out, name=\"pool4_heat_sum\")\n",
    "        self.pool4_up_filters = tf.get_variable(\"pool4_up_filters\", [4, 4, 1, 1], regularizer=self.regularizer)\n",
    "        self.pool4_up = tf.nn.relu(tf.nn.conv2d_transpose(value=self.pool4_heat_sum,\n",
    "                                   filter=self.pool4_up_filters,\n",
    "                                   output_shape=[self.batch_size, 23, 40, 1],\n",
    "                                   strides=[1, 2, 2, 1],\n",
    "                                   name=\"pool4_up\"))\n",
    "        # 23x40\n",
    "        self.pool3_heat_sum = tf.add(self.pool4_up, self.pool3_heat_out, name=\"pool3_heat_sum\")\n",
    "        self.pool3_up_filters = tf.get_variable(\"pool3_up_filters\", [16, 16, 1, 1], regularizer=self.regularizer)\n",
    "        self.pool3_up = tf.nn.relu(tf.nn.conv2d_transpose(value=self.pool3_heat_sum,\n",
    "                                   filter=self.pool3_up_filters,\n",
    "                                   output_shape=[self.batch_size, 180, 320, 1],\n",
    "                                   strides=[1, 8, 8, 1],\n",
    "                                   name=\"pool3_up\"))\n",
    "        self.heatmap_out = self.pool3_up\n",
    "        self.interact_out = self.pool5_heat_out\n",
    "\n",
    "    def build_summary(self):\n",
    "        # summary\n",
    "        tf.summary.scalar(\"heatmap_loss\", self.heatmap_loss)\n",
    "        tf.summary.scalar(\"interact_loss\", self.interact_loss)\n",
    "        tf.summary.scalar(\"total_loss\", self.total_loss)\n",
    "        tf.summary.image(\"input_images\",\n",
    "                         self.input_images,\n",
    "                         max_outputs=self.batch_size*self.frame_num)\n",
    "        \"\"\"\n",
    "        tf.summary.image(\"sample_heatmaps\",\n",
    "                         self.input_images[:,:,:,-self.predicting_dim:],\n",
    "                         max_outputs=self.batch_size*self.frame_num)\n",
    "        \"\"\"\n",
    "        tf.summary.image(\"true_heatmaps\",\n",
    "                         self.true_heats,\n",
    "                         max_outputs=self.batch_size)\n",
    "        tf.summary.image(\"predict_heatmaps\",\n",
    "                         self.predict_heatmaps,\n",
    "                         max_outputs=self.batch_size)\n",
    "        tf.summary.histogram(\"true_interacts\", self.true_interacts)\n",
    "        tf.summary.histogram(\"predict_interacts\", self.predict_interacts)\n",
    "\n",
    "        tf.summary.histogram(\"conv1_activation\", self.conv1)\n",
    "        tf.summary.histogram(\"conv2_activation\", self.conv2)\n",
    "        tf.summary.histogram(\"conv3_activation\", self.conv3)\n",
    "        tf.summary.histogram(\"conv4_activation\", self.conv4)\n",
    "        tf.summary.histogram(\"conv5_activation\", self.conv5)\n",
    "        tf.summary.histogram(\"conv1_gradient\", tf.gradients(self.total_loss, self.conv1))\n",
    "        tf.summary.histogram(\"conv2_gradient\", tf.gradients(self.total_loss, self.conv2))\n",
    "        tf.summary.histogram(\"conv3_gradient\", tf.gradients(self.total_loss, self.conv3))\n",
    "        tf.summary.histogram(\"conv4_gradient\", tf.gradients(self.total_loss, self.conv4))\n",
    "        tf.summary.histogram(\"conv5_gradient\", tf.gradients(self.total_loss, self.conv5))\n",
    "\n",
    "        tf.summary.histogram(\"pool3_heat_out_activation\", self.pool3_heat_out)\n",
    "        tf.summary.histogram(\"pool4_heat_out_activation\", self.pool4_heat_out)\n",
    "        tf.summary.histogram(\"pool5_heat_out_activation\", self.pool5_heat_out)\n",
    "        tf.summary.histogram(\"pool3_heat_out_gradient\", tf.gradients(self.total_loss, self.pool3_heat_out))\n",
    "        tf.summary.histogram(\"pool4_heat_out_gradient\", tf.gradients(self.total_loss, self.pool4_heat_out))\n",
    "        tf.summary.histogram(\"pool5_heat_out_gradient\", tf.gradients(self.total_loss, self.pool5_heat_out))\n",
    "\n",
    "        tf.summary.histogram(\"pool3_up_filters_data\", self.pool3_up_filters)\n",
    "        tf.summary.histogram(\"pool4_up_filters_data\", self.pool4_up_filters)\n",
    "        tf.summary.histogram(\"pool5_up_filters_data\", self.pool5_up_filters)\n",
    "        tf.summary.histogram(\"pool3_up_filters_gradient\", tf.gradients(self.total_loss, self.pool3_up_filters))\n",
    "        tf.summary.histogram(\"pool4_up_filters_gradient\", tf.gradients(self.total_loss, self.pool4_up_filters))\n",
    "        tf.summary.histogram(\"pool5_up_filters_gradient\", tf.gradients(self.total_loss, self.pool5_up_filters))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_data_dir = config_json[\"log_data_dir\"]\n",
    "shutil.rmtree(log_data_dir)\n",
    "os.makedirs(log_data_dir)\n",
    "\n",
    "learning_rate = config_json[\"learning_rate\"]\n",
    "max_iter = config_json[\"max_iter\"]\n",
    "log_step = config_json[\"log_step\"]\n",
    "snapshot_step = config_json[\"snapshot_step\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = MultipleScreenLoader(config_json)\n",
    "model = MultipleScreenModel(config_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_summary = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_config = tf.ConfigProto()\n",
    "tf_config.gpu_options.allow_growth= True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(\"train\")\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver(max_to_keep=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-297356db046d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf_config\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain_writer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFileWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_data_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mfinal_optimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMomentumOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.2/lib/python3.6/site-packages/tensorflow/python/summary/writer/writer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, logdir, graph, max_queue, flush_secs, graph_def, filename_suffix, session)\u001b[0m\n\u001b[1;32m    365\u001b[0m       event_writer = EventFileWriter(logdir, max_queue, flush_secs,\n\u001b[1;32m    366\u001b[0m                                      filename_suffix)\n\u001b[0;32m--> 367\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFileWriter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_writer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_def\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.2/lib/python3.6/site-packages/tensorflow/python/summary/writer/writer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, event_writer, graph, graph_def)\u001b[0m\n\u001b[1;32m     85\u001b[0m       \u001b[0;31m# graph may itself be a graph_def due to positional arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m       maybe_graph_as_def = (graph.as_graph_def(add_shapes=True)\n\u001b[0;32m---> 87\u001b[0;31m                             if isinstance(graph, ops.Graph) else graph)\n\u001b[0m\u001b[1;32m     88\u001b[0m       self.add_meta_graph(\n\u001b[1;32m     89\u001b[0m           meta_graph.create_meta_graph_def(graph_def=graph_def or\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.2/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mas_graph_def\u001b[0;34m(self, from_version, add_shapes)\u001b[0m\n\u001b[1;32m   3122\u001b[0m     \"\"\"\n\u001b[1;32m   3123\u001b[0m     \u001b[0;31m# pylint: enable=line-too-long\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3124\u001b[0;31m     \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_graph_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrom_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3125\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.2/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_as_graph_def\u001b[0;34m(self, from_version, add_shapes)\u001b[0m\n\u001b[1;32m   3092\u001b[0m           \u001b[0mop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nodes_by_name\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3093\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3094\u001b[0;31m             node.attr[\"_output_shapes\"].list.shape.extend(\n\u001b[0m\u001b[1;32m   3095\u001b[0m                 [output.get_shape().as_proto() for output in op.outputs])\n\u001b[1;32m   3096\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_version\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.Session(config=tf_config) as sess:\n",
    "    train_writer = tf.summary.FileWriter(log_data_dir, sess.graph)\n",
    "\n",
    "    final_optimizer = tf.train.MomentumOptimizer(learning_rate, 0.9)\n",
    "\n",
    "    final_trainer = final_optimizer.minimize(model.total_loss)\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        feed_dict = model.get_feed_dict(*data_loader.next_batch())\n",
    "\n",
    "        sess.run(final_trainer, feed_dict=feed_dict)\n",
    "\n",
    "        if i % snapshot_step == 0:\n",
    "            saved_path = saver.save(sess, os.path.join(log_data_dir, \"model_%d.ckpt\" % i))\n",
    "            logger.info(\"model saved in path: %s\" % saved_path)\n",
    "        \n",
    "        if i % log_step ==0:\n",
    "            summary = sess.run(merged_summary, feed_dict=feed_dict)\n",
    "            train_writer.add_summary(summary, i)\n",
    "            train_writer.flush()\n",
    "data_loader.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorboard.notebook'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-19c3dad8e511>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'load_ext'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'tensorboard.notebook'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/3.6.2/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2324\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2325\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2326\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2327\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.2/lib/python3.6/site-packages/decorator.py\u001b[0m in \u001b[0;36mfun\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkwsyntax\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcaller\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextras\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m     \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.2/lib/python3.6/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.2/lib/python3.6/site-packages/IPython/core/magics/extension.py\u001b[0m in \u001b[0;36mload_ext\u001b[0;34m(self, module_str)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodule_str\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mUsageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Missing module name.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextension_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_extension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'already loaded'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.2/lib/python3.6/site-packages/IPython/core/extensions.py\u001b[0m in \u001b[0;36mload_extension\u001b[0;34m(self, module_str)\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmodule_str\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mprepended_to_syspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mipython_extension_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                     \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mipython_extension_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                         print((\"Loading extensions from {dir} is deprecated. \"\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.2/lib/python3.6/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.2/lib/python3.6/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.2/lib/python3.6/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.2/lib/python3.6/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorboard.notebook'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-143-05b429a99399>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m heatmaps = np.stack([[x[0]][:,:,-predicting_dim:]\n\u001b[0;32m----> 2\u001b[0;31m                              for x in input_data[\"trace_0\"]], axis=0)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-143-05b429a99399>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m heatmaps = np.stack([[x[0]][:,:,-predicting_dim:]\n\u001b[0;32m----> 2\u001b[0;31m                              for x in input_data[\"trace_0\"]], axis=0)\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image_num' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-f95014f7ff59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m             \u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mframe_num\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mpredicting_dim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m heatmaps = np.stack([x[0][:,:,-predicting_dim:]\n\u001b[1;32m      5\u001b[0m                             for x in input_data[\"trace_0\"]], axis=0)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'image_num' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<tokenize>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    heatmaps = np.stack([x[0][:,:,-self.predicting_dim:]\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-323533af79a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmaps = np.stack([x[0][:,:,-self.predicting_dim:] for x in input_data[\"trace_0\"]], axis=0)\n",
    "    \n",
    "interacts = np.eye(self.total_interacts)[[x[1][\"interact_type\"] for x in input_data[\"trace_0\"]]]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.DebugSingleScreenLoader'>\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/werverton/DATA/traces/filtered_traces/jp.naver.linecard.android/trace_0/view_hierarchies/13.json', {'interact_type': 0}, (168, 19)]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.11491497, -0.5510944 , -1.9951611 ,  0.82516401],\n",
       "        [-0.19020027, -0.64225303,  0.13209974, -0.46642741],\n",
       "        [-0.61126177,  0.34230667, -0.24379606,  2.19217689]]),\n",
       " array([[ 0.61098618,  2.30553573,  0.56500586, -1.53850315],\n",
       "        [-0.85236358, -0.80890938,  0.5498686 ,  2.32425378],\n",
       "        [ 1.59278725,  0.92651452, -1.05332817, -0.04915212]]),\n",
       " array([[-0.44887249, -0.9834613 ,  0.78494405, -1.71417605],\n",
       "        [ 0.22985371, -0.52957089, -0.11958922,  0.19680375],\n",
       "        [ 0.6136462 , -1.61421579,  0.3229461 , -0.29113052]]),\n",
       " array([[-1.33976936, -0.13098723, -0.17239219, -0.19595837],\n",
       "        [ 0.1859943 , -1.08775161,  1.18169618, -1.82527334],\n",
       "        [ 0.96715911, -0.94447868, -0.21973547, -1.92609474]]),\n",
       " array([[ 0.24748636,  0.81652946, -0.11550025, -0.00345217],\n",
       "        [ 0.68164848,  0.44206775, -0.6146099 ,  1.3465075 ],\n",
       "        [ 2.12580138,  0.57399974, -1.21397099,  0.02364547]]),\n",
       " array([[-0.17962378, -0.87802314, -0.13126707,  0.21478895],\n",
       "        [ 0.16813442,  0.76598165, -0.35941259, -0.93760805],\n",
       "        [-0.04031844, -0.3694133 ,  1.37777513, -1.14002195]]),\n",
       " array([[ 1.24762254, -1.04087776, -0.25468005, -1.58530804],\n",
       "        [ 0.65937753,  0.11701663,  1.15844443,  0.69811339],\n",
       "        [-0.23460634, -0.90199946, -0.28292866, -0.50246028]]),\n",
       " array([[ 0.08402811,  0.43334258, -0.69731402,  0.70674434],\n",
       "        [ 0.85425731,  0.00919997, -0.09371754, -0.38650899],\n",
       "        [-0.28524605, -0.28642545, -1.10764584,  0.84877527]]),\n",
       " array([[ 1.3258405 ,  2.21071024, -0.5902662 , -0.90090219],\n",
       "        [ 0.00340773,  1.51591943, -0.4590002 ,  1.31068281],\n",
       "        [ 2.24661468, -1.13298743,  0.75112102, -0.46237075]]),\n",
       " array([[ 0.94081011,  2.07955541, -1.57509997, -0.49995923],\n",
       "        [ 0.86708081,  0.55906512,  0.30660615, -1.09737838],\n",
       "        [-0.62303541,  0.48291968, -1.71418106, -0.97302438]])]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.stack(arrays, axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 3, 4)\n"
     ]
    }
   ],
   "source": [
    "print(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [['/home/werverton/DATA/traces/filtered_traces/jp.naver.linecard.android/trace_0/view_hierarchies/5.json', {'interact_type': 0}, (165, 102)],\n",
    "['/home/werverton/DATA/traces/filtered_traces/jp.naver.linecard.android/trace_0/view_hierarchies/13.json', {'interact_type': 0}, (168, 19)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/werverton/.pyenv/versions/3.6.2/lib/python3.6/site-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "array_a = np.array(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['/home/werverton/DATA/traces/filtered_traces/jp.naver.linecard.android/trace_0/view_hierarchies/5.json'\n",
      "  {'interact_type': 0} (165, 102)]\n",
      " ['/home/werverton/DATA/traces/filtered_traces/jp.naver.linecard.android/trace_0/view_hierarchies/13.json'\n",
      "  {'interact_type': 0} (168, 19)]]\n"
     ]
    }
   ],
   "source": [
    "print(array_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n"
     ]
    }
   ],
   "source": [
    "print(array_a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.stack(array_a, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['/home/werverton/DATA/traces/filtered_traces/jp.naver.linecard.android/trace_0/view_hierarchies/5.json',\n",
       "        {'interact_type': 0}, (165, 102)],\n",
       "       ['/home/werverton/DATA/traces/filtered_traces/jp.naver.linecard.android/trace_0/view_hierarchies/13.json',\n",
       "        {'interact_type': 0}, (168, 19)]], dtype=object)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_2d = np.array([[[1.73, 1.68, 1.71, 1.89, 1.79],\n",
    "                  [65.4, 59.2, 63.6, 88.4,68.7],\n",
    "                  [1, 2 , 3, 4, 5 ]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.73, 1.68, 1.71, 1.89, 1.79])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_2d[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e002d1c3258916c9835107427e7752803ee2fd90dcf9c80bdd40b882f2eb3aa7"
  },
  "kernelspec": {
   "display_name": "Python 3.6.0 64-bit ('3.6.0': pyenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
